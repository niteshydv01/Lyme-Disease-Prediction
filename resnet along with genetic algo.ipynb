{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "197b589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet import preprocess_input\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d156e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 62s 1us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained ResNet50 model + higher-level layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add global average pooling layer and a dense output layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fa0447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_labels(image_paths, labels):\n",
    "    images = []\n",
    "    valid_labels = []\n",
    "    \n",
    "    for image_path, label in zip(image_paths, labels):\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        if image is None:\n",
    "            print(f\"Warning: Unable to load image at {image_path}. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Detect the ROI using the genetic algorithm\n",
    "        detected_rash = genetic_algorithm(image)\n",
    "        \n",
    "        # Extract ROI and resize to 224x224 for ResNet\n",
    "        x, y, w, h = detected_rash\n",
    "        roi = image[y:y+h, x:x+w]\n",
    "        roi_resized = cv2.resize(roi, (224, 224))\n",
    "        \n",
    "        # Preprocess the image for ResNet\n",
    "        roi_resized = preprocess_input(roi_resized)\n",
    "        \n",
    "        images.append(roi_resized)\n",
    "        valid_labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(valid_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e0960ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_image_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load and preprocess the dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m load_images_and_labels(\u001b[43mtrain_image_paths\u001b[49m, train_labels)\n\u001b[1;32m      3\u001b[0m X_val, y_val \u001b[38;5;241m=\u001b[39m load_images_and_labels(val_image_paths, val_labels)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# One-hot encode labels\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_image_paths' is not defined"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the dataset\n",
    "X_train, y_train = load_images_and_labels(train_image_paths, train_labels)\n",
    "X_val, y_val = load_images_and_labels(val_image_paths, val_labels)\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train = to_categorical(le.fit_transform(y_train), num_classes=2)\n",
    "y_val = to_categorical(le.transform(y_val), num_classes=2)\n",
    "\n",
    "# Data augmentation (optional)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_datagen.flow(X_train, y_train, batch_size=32),\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=2)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c46d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the last few layers of ResNet\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile with a lower learning rate\n",
    "model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Continue training (fine-tuning)\n",
    "history_fine = model.fit(\n",
    "    train_datagen.flow(X_train, y_train, batch_size=32),\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbfbe36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n",
      "libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n",
      "libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n",
      "libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n",
      "libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n",
      "libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n",
      "libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n",
      "libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unable to load image at /Users/niteshyadav/Lyme_Disease/Train_rash/Train_2_Cases/Negative/fixed drug reaction75.jpg. Skipping...\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 21s 822ms/step - loss: 1.6930 - accuracy: 0.5309 - val_loss: 621.5412 - val_accuracy: 0.4138\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 19s 816ms/step - loss: 0.7644 - accuracy: 0.5927 - val_loss: 2175.8862 - val_accuracy: 0.4138\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 19s 820ms/step - loss: 0.7162 - accuracy: 0.5730 - val_loss: 2.6880 - val_accuracy: 0.5862\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 19s 823ms/step - loss: 0.7151 - accuracy: 0.5758 - val_loss: 0.6923 - val_accuracy: 0.5977\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 19s 814ms/step - loss: 0.6940 - accuracy: 0.5758 - val_loss: 0.6906 - val_accuracy: 0.5862\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 19s 831ms/step - loss: 0.6706 - accuracy: 0.6236 - val_loss: 0.6919 - val_accuracy: 0.5862\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 19s 815ms/step - loss: 0.6704 - accuracy: 0.6124 - val_loss: 0.6917 - val_accuracy: 0.5862\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 19s 843ms/step - loss: 0.6754 - accuracy: 0.6011 - val_loss: 0.6816 - val_accuracy: 0.5862\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 19s 823ms/step - loss: 0.6648 - accuracy: 0.6096 - val_loss: 0.6894 - val_accuracy: 0.5862\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 19s 825ms/step - loss: 0.6520 - accuracy: 0.6124 - val_loss: 0.6939 - val_accuracy: 0.4138\n",
      "3/3 [==============================] - 1s 341ms/step\n",
      "Validation Accuracy: 0.41\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from skimage.feature import local_binary_pattern\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Paths to the dataset folders\n",
    "train_path = \"/Users/niteshyadav/Lyme_Disease/Train_rash/Train_2_Cases\"\n",
    "val_path = \"/Users/niteshyadav/Lyme_Disease/Validation_rash/Validation_2_Cases\"\n",
    "\n",
    "def load_image_paths_and_labels(data_dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in ['Positive', 'Negative']:\n",
    "        label_dir = os.path.join(data_dir, label)\n",
    "        for image_name in os.listdir(label_dir):\n",
    "            image_paths.append(os.path.join(label_dir, image_name))\n",
    "            labels.append(label)\n",
    "    return image_paths, labels\n",
    "\n",
    "# Load paths and labels for training and validation data\n",
    "train_image_paths, train_labels = load_image_paths_and_labels(train_path)\n",
    "val_image_paths, val_labels = load_image_paths_and_labels(val_path)\n",
    "\n",
    "def initialize_population(image, pop_size=10):\n",
    "    population = []\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    _, thresh = cv2.threshold(gray_image, 200, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    lower_red1 = np.array([0, 50, 50])\n",
    "    upper_red1 = np.array([10, 255, 255])\n",
    "    lower_red2 = np.array([170, 50, 50])\n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "    mask1 = cv2.inRange(hsv_image, lower_red1, upper_red1)\n",
    "    mask2 = cv2.inRange(hsv_image, lower_red2, upper_red2)\n",
    "    red_mask = mask1 + mask2\n",
    "    \n",
    "    combined_mask = cv2.bitwise_and(thresh, red_mask)\n",
    "    \n",
    "    contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for contour in contours[:pop_size]:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        population.append((x, y, w, h))\n",
    "    \n",
    "    h, w = gray_image.shape\n",
    "    while len(population) < pop_size:\n",
    "        rand_x = random.randint(0, w - 50)\n",
    "        rand_y = random.randint(0, h - 50)\n",
    "        width = random.randint(10, 50)\n",
    "        height = random.randint(10, 50)\n",
    "        population.append((rand_x, rand_y, width, height))\n",
    "    \n",
    "    return population\n",
    "\n",
    "def fitness_function(candidate, image):\n",
    "    x, y, w, h = candidate\n",
    "    roi = image[y:y+h, x:x+w]\n",
    "    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    lower_red1 = np.array([0, 50, 50])\n",
    "    upper_red1 = np.array([10, 255, 255])\n",
    "    lower_red2 = np.array([170, 50, 50])\n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "    mask1 = cv2.inRange(hsv_roi, lower_red1, upper_red1)\n",
    "    mask2 = cv2.inRange(hsv_roi, lower_red2, upper_red2)\n",
    "    red_mask = mask1 + mask2\n",
    "    red_area = np.sum(red_mask) / (w * h)\n",
    "    \n",
    "    aspect_ratio = float(w) / h\n",
    "    shape_score = 1.0 if 0.75 <= aspect_ratio <= 1.25 else 0.5\n",
    "    \n",
    "    gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    lbp = local_binary_pattern(gray_roi, P=8, R=1, method='uniform')\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, 27), range=(0, 26))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-6)\n",
    "    texture_score = np.mean(hist)\n",
    "    \n",
    "    fitness = red_area * 0.4 + shape_score * 0.3 + texture_score * 0.3\n",
    "    return fitness\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    x1, y1, w1, h1 = parent1\n",
    "    x2, y2, w2, h2 = parent2\n",
    "    child1 = (x1, y2, w1, h2)\n",
    "    child2 = (x2, y1, w2, h1)\n",
    "    return child1, child2\n",
    "\n",
    "def mutate(candidate, image_shape, mutation_rate=0.1):\n",
    "    if random.random() < mutation_rate:\n",
    "        h, w = image_shape[:2]\n",
    "        x, y, width, height = candidate\n",
    "        x = random.randint(0, w - 50)\n",
    "        y = random.randint(0, h - 50)\n",
    "        width = random.randint(10, 50)\n",
    "        height = random.randint(10, 50)\n",
    "        candidate = (x, y, width, height)\n",
    "    return candidate\n",
    "\n",
    "def select(population, fitnesses, num_to_select):\n",
    "    selected = list(zip(population, fitnesses))\n",
    "    selected.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [candidate for candidate, fitness in selected[:num_to_select]]\n",
    "\n",
    "def genetic_algorithm(image, num_generations=20, pop_size=10, mutation_rate=0.1):\n",
    "    population = initialize_population(image, pop_size)\n",
    "    for generation in range(num_generations):\n",
    "        fitnesses = [fitness_function(candidate, image) for candidate in population]\n",
    "        population = select(population, fitnesses, pop_size // 2)\n",
    "        new_population = []\n",
    "        while len(new_population) < pop_size:\n",
    "            parent1, parent2 = random.sample(population, 2)\n",
    "            child1, child2 = crossover(parent1, parent2)\n",
    "            new_population.append(mutate(child1, image.shape, mutation_rate))\n",
    "            new_population.append(mutate(child2, image.shape, mutation_rate))\n",
    "        population = new_population\n",
    "    best_candidate = max(population, key=lambda candidate: fitness_function(candidate, image))\n",
    "    return best_candidate\n",
    "\n",
    "# Load pre-trained ResNet50 model + custom layers for transfer learning\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model using the legacy Adam optimizer\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def load_images_and_labels(image_paths, labels):\n",
    "    data = []\n",
    "    valid_labels = []\n",
    "    \n",
    "    for image_path, label in zip(image_paths, labels):\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        if image is None:\n",
    "            print(f\"Warning: Unable to load image at {image_path}. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        detected_rash = genetic_algorithm(image)\n",
    "        roi = image[detected_rash[1]:detected_rash[1] + detected_rash[3], detected_rash[0]:detected_rash[0] + detected_rash[2]]\n",
    "        roi_resized = cv2.resize(roi, (150, 150))\n",
    "        data.append(roi_resized)\n",
    "        valid_labels.append(label)\n",
    "    \n",
    "    return np.array(data), np.array(valid_labels)\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "X_train, y_train = load_images_and_labels(train_image_paths, train_labels)\n",
    "X_val, y_val = load_images_and_labels(val_image_paths, val_labels)\n",
    "\n",
    "# Normalize the images\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "\n",
    "# Encode labels and one-hot encode them\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_val = to_categorical(y_val, num_classes=2)\n",
    "\n",
    "# Create data generators for augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "# Training the model\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "\n",
    "model.fit(\n",
    "    train_datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "    validation_data=val_datagen.flow(X_val, y_val, batch_size=batch_size),\n",
    "    epochs=epochs,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_val_pred = np.argmax(y_val_pred, axis=1)\n",
    "y_val_true = np.argmax(y_val, axis=1)\n",
    "accuracy = accuracy_score(y_val_true, y_val_pred)\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4f7d30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
