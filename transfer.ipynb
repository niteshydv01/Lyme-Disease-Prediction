{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3436cb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, DenseNet121, MobileNetV2, Xception, NASNetMobile, EfficientNetB0\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers.legacy import Adam  # Use the legacy optimizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Genetic Algorithm Segmentation\n",
    "def genetic_algorithm_segment(image, population_size=20, generations=10):\n",
    "    def initialize_population(pop_size):\n",
    "        return np.random.randint(0, 256, pop_size)\n",
    "    \n",
    "    def fitness_function(image, threshold):\n",
    "        _, binary_img = cv2.threshold(image, threshold, 255, cv2.THRESH_BINARY)\n",
    "        return cv2.countNonZero(binary_img)\n",
    "\n",
    "    def selection(population, fitness_scores):\n",
    "        sorted_idx = np.argsort(fitness_scores)\n",
    "        return population[sorted_idx[-2:]]  # Select top 2\n",
    "    \n",
    "    def crossover(parents):\n",
    "        crossover_point = np.random.randint(0, 8)\n",
    "        child1 = (parents[0] & (255 << crossover_point)) | (parents[1] & (255 >> (8 - crossover_point)))\n",
    "        child2 = (parents[1] & (255 << crossover_point)) | (parents[0] & (255 >> (8 - crossover_point)))\n",
    "        return [child1, child2]\n",
    "\n",
    "    def mutation(offspring):\n",
    "        mutation_point = np.random.randint(0, 8)\n",
    "        return [offspring[0] ^ (1 << mutation_point), offspring[1] ^ (1 << mutation_point)]\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    population = initialize_population(population_size)\n",
    "    for generation in range(generations):\n",
    "        fitness_scores = [fitness_function(gray, threshold) for threshold in population]\n",
    "        parents = selection(population, fitness_scores)\n",
    "        offspring = crossover(parents)\n",
    "        population = np.concatenate((parents, mutation(offspring)))\n",
    "    \n",
    "    best_threshold = population[np.argmax([fitness_function(gray, threshold) for threshold in population])]\n",
    "    _, segmented = cv2.threshold(gray, best_threshold, 255, cv2.THRESH_BINARY)\n",
    "    return segmented\n",
    "\n",
    "# Grad-CAM Implementation\n",
    "class GradCAM:\n",
    "    def __init__(self, model, layerName):\n",
    "        self.model = model\n",
    "        self.layerName = layerName\n",
    "        self.gradModel = tf.keras.models.Model(\n",
    "            inputs=[model.inputs],\n",
    "            outputs=[model.get_layer(layerName).output, model.output])\n",
    "\n",
    "    def compute_heatmap(self, image, eps=1e-8):\n",
    "        with tf.GradientTape() as tape:\n",
    "            inputs = tf.cast(image, tf.float32)\n",
    "            (convOutputs, predictions) = self.gradModel(inputs)\n",
    "            loss = predictions[:, 0]\n",
    "\n",
    "        grads = tape.gradient(loss, convOutputs)\n",
    "        castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n",
    "        castGrads = tf.cast(grads > 0, \"float32\")\n",
    "        guidedGrads = castConvOutputs * castGrads * grads\n",
    "        convOutputs = convOutputs[0]\n",
    "        guidedGrads = guidedGrads[0]\n",
    "        weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n",
    "        cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n",
    "        (w, h) = (image.shape[2], image.shape[1])\n",
    "        heatmap = cv2.resize(cam.numpy(), (w, h))\n",
    "        numer = heatmap - np.min(heatmap)\n",
    "        denom = (heatmap.max() - heatmap.min()) + eps\n",
    "        heatmap = numer / denom\n",
    "        return heatmap\n",
    "\n",
    "    def overlay_heatmap(self, heatmap, image, alpha=0.5, colormap=cv2.COLORMAP_JET):\n",
    "        heatmap = cv2.applyColorMap((heatmap * 255).astype(\"uint8\"), colormap)\n",
    "        output = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\n",
    "        return output\n",
    "\n",
    "# Paths to the dataset folders\n",
    "train_path = \"/Users/niteshyadav/Lyme_Disease/train\"\n",
    "val_path = \"/Users/niteshyadav/Lyme_Disease/val\"\n",
    "test_path = \"/Users/niteshyadav/Lyme_Disease/test\"\n",
    "\n",
    "# Function to segment images using Genetic Algorithm\n",
    "def segment_images(input_folder, output_folder):\n",
    "    for subdir, _, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            img_path = os.path.join(subdir, file)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"Failed to load image: {img_path}\")\n",
    "                continue\n",
    "            segmented_img = genetic_algorithm_segment(img)  # Segment the image using GA\n",
    "            output_subdir = os.path.join(output_folder, os.path.basename(subdir))\n",
    "            os.makedirs(output_subdir, exist_ok=True)\n",
    "            cv2.imwrite(os.path.join(output_subdir, file), segmented_img)\n",
    "\n",
    "# Segment train, val, and test images\n",
    "segment_images(train_path, train_path + \"_segmented\")\n",
    "segment_images(val_path, val_path + \"_segmented\")\n",
    "segment_images(test_path, test_path + \"_segmented\")\n",
    "\n",
    "# Data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_path + \"_segmented\", target_size=(224, 224), batch_size=32, class_mode='binary')\n",
    "val_generator = val_datagen.flow_from_directory(val_path + \"_segmented\", target_size=(224, 224), batch_size=32, class_mode='binary')\n",
    "test_generator = test_datagen.flow_from_directory(test_path + \"_segmented\", target_size=(224, 224), batch_size=32, class_mode='binary', shuffle=False)\n",
    "\n",
    "# Function to build and compile CNN model\n",
    "def build_model(architecture, input_shape=(224, 224, 3)):\n",
    "    if architecture == 'VGG16':\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif architecture == 'ResNet50':\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif architecture == 'DenseNet121':\n",
    "        base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif architecture == 'MobileNetV2':\n",
    "        base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif architecture == 'Xception':\n",
    "        base_model = Xception(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif architecture == 'NASNetMobile':\n",
    "        base_model = NASNetMobile(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif architecture == 'EfficientNetB0':\n",
    "        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown architecture\")\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train and evaluate models\n",
    "architectures = ['VGG16', 'ResNet50', 'DenseNet121', 'MobileNetV2', 'Xception', 'NASNetMobile', 'EfficientNetB0']\n",
    "for architecture in architectures:\n",
    "    model = build_model(architecture)\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "        ModelCheckpoint(f'{architecture}_best_model.h5', save_best_only=True)\n",
    "    ]\n",
    "    model.fit(train_generator, validation_data=val_generator, epochs=50, callbacks=callbacks)\n",
    "    model.evaluate(test_generator)\n",
    "\n",
    "    # Grad-CAM for model explainability\n",
    "    grad_cam = GradCAM(model, 'block5_conv3')  # Replace 'block5_conv3' with the name of the last conv layer of the model\n",
    "    for img_path in test_generator.filepaths:\n",
    "        img = cv2.imread(img_path)\n",
    "        img_preprocessed = cv2.resize(img, (224, 224))\n",
    "        img_preprocessed = np.expand_dims(img_preprocessed, axis=0)\n",
    "        heatmap = grad_cam.compute_heatmap(img_preprocessed)\n",
    "        heatmap_img = grad_cam.overlay_heatmap(heatmap, img)\n",
    "        cv2.imshow('Grad-CAM', heatmap_img)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Hyperparameter tuning code (not fully implemented, as it's a complex process involving libraries like Keras Tuner or Optuna)\n",
    "# This example shows a simple grid search approach for learning rate tuning\n",
    "for lr in [1e-4, 1e-5, 1e-6]:\n",
    "    model = build_model('ResNet50')  # Example with ResNet50\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(train_generator, validation_data=val_generator, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d8ad7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4046 images belonging to 2 classes.\n",
      "Found 506 images belonging to 2 classes.\n",
      "Found 507 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "127/127 [==============================] - 387s 3s/step - loss: 0.5123 - accuracy: 0.8087 - val_loss: 0.4809 - val_accuracy: 0.8142 - lr: 1.0000e-04\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niteshyadav/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 392s 3s/step - loss: 0.4953 - accuracy: 0.8136 - val_loss: 0.4806 - val_accuracy: 0.8142 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "127/127 [==============================] - 402s 3s/step - loss: 0.4964 - accuracy: 0.8139 - val_loss: 0.4808 - val_accuracy: 0.8142 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "127/127 [==============================] - 394s 3s/step - loss: 0.4907 - accuracy: 0.8141 - val_loss: 0.4794 - val_accuracy: 0.8142 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "127/127 [==============================] - 390s 3s/step - loss: 0.4864 - accuracy: 0.8141 - val_loss: 0.4797 - val_accuracy: 0.8142 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "127/127 [==============================] - 400s 3s/step - loss: 0.4844 - accuracy: 0.8141 - val_loss: 0.4796 - val_accuracy: 0.8142 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "127/127 [==============================] - 383s 3s/step - loss: 0.4849 - accuracy: 0.8141 - val_loss: 0.4804 - val_accuracy: 0.8142 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "127/127 [==============================] - 382s 3s/step - loss: 0.4899 - accuracy: 0.8141 - val_loss: 0.4796 - val_accuracy: 0.8142 - lr: 1.0000e-05\n",
      "Epoch 9/20\n",
      "127/127 [==============================] - 389s 3s/step - loss: 0.4853 - accuracy: 0.8141 - val_loss: 0.4795 - val_accuracy: 0.8142 - lr: 1.0000e-05\n",
      " 8/16 [==============>...............] - ETA: 21s - loss: 0.2103 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, DenseNet121, MobileNetV2, Xception, NASNetMobile, EfficientNetB0\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Genetic Algorithm Segmentation\n",
    "def genetic_algorithm_segment(image, population_size=20, generations=10):\n",
    "    def initialize_population(pop_size):\n",
    "        return np.random.randint(0, 256, pop_size)\n",
    "    \n",
    "    def fitness_function(image, threshold):\n",
    "        _, binary_img = cv2.threshold(image, threshold, 255, cv2.THRESH_BINARY)\n",
    "        return cv2.countNonZero(binary_img)\n",
    "\n",
    "    def selection(population, fitness_scores):\n",
    "        sorted_idx = np.argsort(fitness_scores)\n",
    "        return population[sorted_idx[-2:]]  # Select top 2\n",
    "    \n",
    "    def crossover(parents):\n",
    "        crossover_point = np.random.randint(0, 8)\n",
    "        child1 = (parents[0] & (255 << crossover_point)) | (parents[1] & (255 >> (8 - crossover_point)))\n",
    "        child2 = (parents[1] & (255 << crossover_point)) | (parents[0] & (255 >> (8 - crossover_point)))\n",
    "        return [child1, child2]\n",
    "\n",
    "    def mutation(offspring):\n",
    "        mutation_point = np.random.randint(0, 8)\n",
    "        return [offspring[0] ^ (1 << mutation_point), offspring[1] ^ (1 << mutation_point)]\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    population = initialize_population(population_size)\n",
    "    for generation in range(generations):\n",
    "        fitness_scores = [fitness_function(gray, threshold) for threshold in population]\n",
    "        parents = selection(population, fitness_scores)\n",
    "        offspring = crossover(parents)\n",
    "        population = np.concatenate((parents, mutation(offspring)))\n",
    "    \n",
    "    best_threshold = population[np.argmax([fitness_function(gray, threshold) for threshold in population])]\n",
    "    _, segmented = cv2.threshold(gray, best_threshold, 255, cv2.THRESH_BINARY)\n",
    "    return segmented\n",
    "\n",
    "# Grad-CAM Implementation\n",
    "class GradCAM:\n",
    "    def __init__(self, model, layerName):\n",
    "        self.model = model\n",
    "        self.layerName = layerName\n",
    "        self.gradModel = tf.keras.models.Model(\n",
    "            inputs=[model.inputs],\n",
    "            outputs=[model.get_layer(layerName).output, model.output])\n",
    "\n",
    "    def compute_heatmap(self, image, eps=1e-8):\n",
    "        with tf.GradientTape() as tape:\n",
    "            inputs = tf.cast(image, tf.float32)\n",
    "            (convOutputs, predictions) = self.gradModel(inputs)\n",
    "            loss = predictions[:, 0]\n",
    "\n",
    "        grads = tape.gradient(loss, convOutputs)\n",
    "        castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n",
    "        castGrads = tf.cast(grads > 0, \"float32\")\n",
    "        guidedGrads = castConvOutputs * castGrads * grads\n",
    "        convOutputs = convOutputs[0]\n",
    "        guidedGrads = guidedGrads[0]\n",
    "        weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n",
    "        cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n",
    "        (w, h) = (image.shape[2], image.shape[1])\n",
    "        heatmap = cv2.resize(cam.numpy(), (w, h))\n",
    "        numer = heatmap - np.min(heatmap)\n",
    "        denom = (heatmap.max() - heatmap.min()) + eps\n",
    "        heatmap = numer / denom\n",
    "        return heatmap\n",
    "\n",
    "    def overlay_heatmap(self, heatmap, image, alpha=0.5, colormap=cv2.COLORMAP_JET):\n",
    "        heatmap = cv2.applyColorMap((heatmap * 255).astype(\"uint8\"), colormap)\n",
    "        output = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\n",
    "        return output\n",
    "\n",
    "# Paths to the dataset folders\n",
    "train_path = \"/Users/niteshyadav/Lyme_Disease/train\"\n",
    "val_path = \"/Users/niteshyadav/Lyme_Disease/val\"\n",
    "test_path = \"/Users/niteshyadav/Lyme_Disease/test\"\n",
    "\n",
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_path + \"_segmented\", target_size=(224, 224), batch_size=32, class_mode='binary')\n",
    "val_generator = val_datagen.flow_from_directory(val_path + \"_segmented\", target_size=(224, 224), batch_size=32, class_mode='binary')\n",
    "test_generator = test_datagen.flow_from_directory(test_path + \"_segmented\", target_size=(224, 224), batch_size=32, class_mode='binary', shuffle=False)\n",
    "\n",
    "# Model building and training\n",
    "def build_model(architecture, input_shape=(224, 224, 3)):\n",
    "    if architecture == 'VGG16':\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif architecture == 'ResNet50':\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif architecture == 'DenseNet121':\n",
    "        base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif architecture == 'MobileNetV2':\n",
    "        base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif architecture == 'Xception':\n",
    "        base_model = Xception(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif architecture == 'NASNetMobile':\n",
    "        base_model = NASNetMobile(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif architecture == 'EfficientNetB0':\n",
    "        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown architecture\")\n",
    "\n",
    "    # Freeze the base model\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Training and evaluating models\n",
    "architectures = ['VGG16', 'ResNet50', 'DenseNet121', 'MobileNetV2', 'Xception', 'NASNetMobile', 'EfficientNetB0']\n",
    "for architecture in architectures:\n",
    "    model = build_model(architecture)\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "        ModelCheckpoint(f'{architecture}_best_model.h5', save_best_only=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)\n",
    "    ]\n",
    "    model.fit(train_generator, validation_data=val_generator, epochs=20, callbacks=callbacks)\n",
    "    model.evaluate(test_generator)\n",
    "\n",
    "    # Grad-CAM for model explainability\n",
    "    grad_cam = GradCAM(model, 'block5_conv3')  # Replace 'block5_conv3' with the name of the last conv layer of the model\n",
    "    for img_path in test_generator.filepaths:\n",
    "        img = cv2.imread(img_path)\n",
    "        img_preprocessed = cv2.resize(img, (224, 224))\n",
    "        img_preprocessed = np.expand_dims(img_preprocessed, axis=0)\n",
    "        heatmap = grad_cam.compute_heatmap(img_preprocessed)\n",
    "        heatmap_img = grad_cam.overlay_heatmap(heatmap, img)\n",
    "        cv2.imshow('Grad-CAM', heatmap_img)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Hyperparameter tuning code (not fully implemented, as it's a complex process involving libraries like Keras Tuner or Optuna)\n",
    "# This example shows a simple grid search approach for learning rate tuning\n",
    "for lr in [1e-4, 1e-5, 1e-6]:\n",
    "    model = build_model('ResNet50')  # Example with ResNet50\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(train_generator, validation_data=val_generator, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b07cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
