{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b5b97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n",
      "libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n",
      "libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n",
      "libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n",
      "libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n",
      "libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n",
      "libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n",
      "libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image /Users/niteshyadav/Lyme_Disease/Train_rash/Train_2_Cases/Negative/fixed drug reaction75.jpg. Skipping.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niteshyadav/anaconda3/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 5s/step - accuracy: 0.5048 - loss: 2.6010 - val_accuracy: 0.5862 - val_loss: 0.6770\n",
      "Epoch 2/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 5s/step - accuracy: 0.5065 - loss: 2.4284 - val_accuracy: 0.5747 - val_loss: 0.6877\n",
      "Epoch 3/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 5s/step - accuracy: 0.4849 - loss: 2.1853 - val_accuracy: 0.5862 - val_loss: 0.6804\n",
      "Epoch 4/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 5s/step - accuracy: 0.5243 - loss: 2.6200 - val_accuracy: 0.5862 - val_loss: 0.7338\n",
      "Epoch 5/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 5s/step - accuracy: 0.4687 - loss: 2.5496 - val_accuracy: 0.5862 - val_loss: 0.6978\n",
      "Epoch 6/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 5s/step - accuracy: 0.5720 - loss: 1.9316 - val_accuracy: 0.5862 - val_loss: 0.7844\n",
      "Epoch 7/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 5s/step - accuracy: 0.4848 - loss: 2.3962 - val_accuracy: 0.5632 - val_loss: 0.6855\n",
      "Epoch 8/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 5s/step - accuracy: 0.5338 - loss: 2.0095 - val_accuracy: 0.5862 - val_loss: 0.9716\n",
      "Epoch 9/100\n",
      "\u001b[1m23/45\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:53\u001b[0m 5s/step - accuracy: 0.4826 - loss: 1.9580"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from skimage.feature import local_binary_pattern\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def preprocess_input(x):\n",
    "    x = x.astype('float32')\n",
    "    x /= 127.5\n",
    "    x -= 1.\n",
    "    return x\n",
    "\n",
    "# Paths to the dataset folders\n",
    "train_path = \"/Users/niteshyadav/Lyme_Disease/Train_rash/Train_2_Cases\"\n",
    "val_path = \"/Users/niteshyadav/Lyme_Disease/Validation_rash/Validation_2_Cases\"\n",
    "\n",
    "def load_image_paths_and_labels(data_dir): \n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in ['Positive', 'Negative']:\n",
    "        label_dir = os.path.join(data_dir, label)\n",
    "        for image_name in os.listdir(label_dir):\n",
    "            image_paths.append(os.path.join(label_dir, image_name))\n",
    "            labels.append(1 if label == 'Positive' else 0)  # Convert labels to numerical values\n",
    "    return image_paths, labels\n",
    "\n",
    "# Load paths and labels for training and validation data\n",
    "train_image_paths, train_labels = load_image_paths_and_labels(train_path)\n",
    "val_image_paths, val_labels = load_image_paths_and_labels(val_path)\n",
    "\n",
    "def initialize_population(image, pop_size=10):\n",
    "    population = []\n",
    "    \n",
    "    if image is None:\n",
    "        raise ValueError(\"Image is empty. Check the file path.\")\n",
    "    \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Thresholding to find high-intensity regions\n",
    "    _, thresh = cv2.threshold(gray_image, 200, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Red color mask\n",
    "    lower_red = np.array([0, 50, 50])\n",
    "    upper_red = np.array([10, 255, 255])\n",
    "    mask1 = cv2.inRange(hsv_image, lower_red, upper_red)\n",
    "    \n",
    "    lower_red = np.array([170, 50, 50])\n",
    "    upper_red = np.array([180, 255, 255])\n",
    "    mask2 = cv2.inRange(hsv_image, lower_red, upper_red)\n",
    "    \n",
    "    red_mask = mask1 + mask2\n",
    "    \n",
    "    # Combine masks\n",
    "    combined_mask = cv2.bitwise_and(thresh, red_mask)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Initialize population with bounding boxes of detected regions\n",
    "    for contour in contours[:pop_size]:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        population.append((x, y, w, h))\n",
    "    \n",
    "    # If not enough regions, fill with random regions\n",
    "    while len(population) < pop_size:\n",
    "        h, w = gray_image.shape\n",
    "        x = random.randint(0, w-1)\n",
    "        y = random.randint(0, h-1)\n",
    "        width = random.randint(10, 50)\n",
    "        height = random.randint(10, 50)\n",
    "        population.append((x, y, width, height))\n",
    "    \n",
    "    return population\n",
    "\n",
    "def fitness_function(candidate, image):\n",
    "    x, y, w, h = candidate\n",
    "    roi = image[y:y+h, x:x+w]\n",
    "    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Calculate redness\n",
    "    lower_red = np.array([0, 50, 50])\n",
    "    upper_red = np.array([10, 255, 255])\n",
    "    mask1 = cv2.inRange(hsv_roi, lower_red, upper_red)\n",
    "    \n",
    "    lower_red = np.array([170, 50, 50])\n",
    "    upper_red = np.array([180, 255, 255])\n",
    "    mask2 = cv2.inRange(hsv_roi, lower_red, upper_red)\n",
    "    red_mask = mask1 + mask2\n",
    "    red_area = np.sum(red_mask) / (w * h)\n",
    "    \n",
    "    # Shape: prefer circular or oval shapes\n",
    "    aspect_ratio = float(w) / h\n",
    "    shape_score = 1.0 if 0.75 <= aspect_ratio <= 1.25 else 0.5\n",
    "    \n",
    "    # Texture: use LBP to score texture\n",
    "    gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    lbp = local_binary_pattern(gray_roi, P=8, R=1, method='uniform')\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, 27), range=(0, 26))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-6)\n",
    "    texture_score = np.mean(hist)\n",
    "    \n",
    "    # Combine scores\n",
    "    fitness = red_area * 0.4 + shape_score * 0.3 + texture_score * 0.3\n",
    "    return fitness\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    x1, y1, w1, h1 = parent1\n",
    "    x2, y2, w2, h2 = parent2\n",
    "    child1 = (x1, y2, w1, h2)\n",
    "    child2 = (x2, y1, w2, h1)\n",
    "    return child1, child2\n",
    "\n",
    "def mutate(candidate, image_shape, mutation_rate=0.1):\n",
    "    if random.random() < mutation_rate:\n",
    "        h, w, _ = image_shape\n",
    "        x, y, w, h = candidate\n",
    "        x = random.randint(0, w-1)\n",
    "        y = random.randint(0, h-1)\n",
    "        width = random.randint(10, 50)\n",
    "        height = random.randint(10, 50)\n",
    "        candidate = (x, y, width, height)\n",
    "    return candidate\n",
    "\n",
    "def select(population, fitnesses, num_to_select):\n",
    "    selected = list(zip(population, fitnesses))\n",
    "    selected.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [candidate for candidate, fitness in selected[:num_to_select]]\n",
    "\n",
    "def genetic_algorithm(image, num_generations=20, pop_size=10, mutation_rate=0.1):\n",
    "    population = initialize_population(image, pop_size)\n",
    "    for generation in range(num_generations):\n",
    "        fitnesses = [fitness_function(candidate, image) for candidate in population]\n",
    "        population = select(population, fitnesses, pop_size // 2)\n",
    "        new_population = []\n",
    "        while len(new_population) < pop_size:\n",
    "            parent1, parent2 = random.sample(population, 2)\n",
    "            child1, child2 = crossover(parent1, parent2)\n",
    "            new_population.append(mutate(child1, image.shape, mutation_rate))\n",
    "            new_population.append(mutate(child2, image.shape, mutation_rate))\n",
    "        population = new_population\n",
    "    best_candidate = max(population, key=lambda candidate: fitness_function(candidate, image))\n",
    "    return best_candidate\n",
    "\n",
    "def extract_roi_and_preprocess(image_paths, labels):\n",
    "    preprocessed_images = []\n",
    "    filtered_labels = []\n",
    "    for image_path, label in zip(image_paths, labels):\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        # Check if the image is loaded successfully\n",
    "        if image is None:\n",
    "            print(f\"Warning: Could not load image {image_path}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        detected_rash = genetic_algorithm(image)\n",
    "        x, y, w, h = detected_rash\n",
    "        roi = image[y:y+h, x:x+w]\n",
    "        roi_resized = cv2.resize(roi, (300, 300))\n",
    "        preprocessed_images.append(roi_resized)\n",
    "        filtered_labels.append(label)  # Keep the label in sync\n",
    "    \n",
    "    return np.array(preprocessed_images), np.array(filtered_labels)\n",
    "\n",
    "# Preprocess the ROIs\n",
    "X_train, train_labels_filtered = extract_roi_and_preprocess(train_image_paths, train_labels)\n",
    "X_val, val_labels_filtered = extract_roi_and_preprocess(val_image_paths, val_labels)\n",
    "\n",
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                   rotation_range=90,\n",
    "                                   horizontal_flip=True,\n",
    "                                   zoom_range=0.1)\n",
    "\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, train_labels_filtered, batch_size=8)\n",
    "val_generator = val_datagen.flow(X_val, val_labels_filtered, batch_size=8)\n",
    "\n",
    "# Define the model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_generator, epochs=100, validation_data=val_generator, shuffle=True)\n",
    "\n",
    "# Save the model weights\n",
    "model.save_weights(\"model_with_roi_extraction.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a89d18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
