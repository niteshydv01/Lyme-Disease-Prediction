{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46d7fd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "126/126 [==============================] - 52s 407ms/step - loss: 158.5576 - accuracy: 0.9613 - val_loss: 549.7802 - val_accuracy: 0.8042\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niteshyadav/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 48s 379ms/step - loss: 91.0260 - accuracy: 0.9287 - val_loss: 57.7530 - val_accuracy: 0.8692\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 48s 382ms/step - loss: 26.9496 - accuracy: 0.9400 - val_loss: 119.6336 - val_accuracy: 0.8692\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 48s 379ms/step - loss: 35.7784 - accuracy: 0.8854 - val_loss: 4.8244 - val_accuracy: 0.8650\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 47s 374ms/step - loss: 2.1390 - accuracy: 0.8513 - val_loss: 11.1926 - val_accuracy: 0.8017\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 47s 377ms/step - loss: 3.0985 - accuracy: 0.8468 - val_loss: 18.2651 - val_accuracy: 0.8017\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 47s 375ms/step - loss: 5.3485 - accuracy: 0.6652 - val_loss: 3.1143 - val_accuracy: 0.8017\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 48s 379ms/step - loss: 2.4493 - accuracy: 0.3685 - val_loss: 4.5265 - val_accuracy: 0.8017\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 48s 379ms/step - loss: 1.3005 - accuracy: 0.1986 - val_loss: 0.7591 - val_accuracy: 0.2004\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 47s 377ms/step - loss: 0.7111 - accuracy: 0.1876 - val_loss: 0.7421 - val_accuracy: 0.2004\n",
      "16/16 [==============================] - 2s 103ms/step\n",
      "Combined Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      0.00      0.01       412\n",
      "    Positive       0.19      1.00      0.32        95\n",
      "\n",
      "    accuracy                           0.19       507\n",
      "   macro avg       0.59      0.50      0.16       507\n",
      "weighted avg       0.85      0.19      0.07       507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Concatenate, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Paths to the dataset folders\n",
    "train_path = \"/Users/niteshyadav/Lyme_Disease/train\"\n",
    "test_path = \"/Users/niteshyadav/Lyme_Disease/test\"\n",
    "val_path = \"/Users/niteshyadav/Lyme_Disease/val\"\n",
    "\n",
    "\n",
    "# Function to extract LBP features from the image\n",
    "def extract_lbp_features(image):\n",
    "    lbp = local_binary_pattern(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), P=8, R=1, method='uniform')\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, 27), range=(0, 26))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-6)\n",
    "    return hist\n",
    "\n",
    "# Generator to yield batches of images and LBP features\n",
    "def image_lbp_generator(path, batch_size=32, augment=False):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    ) if augment else None\n",
    "    \n",
    "    while True:\n",
    "        images = []\n",
    "        lbp_features = []\n",
    "        labels = []\n",
    "        for label in ['Positive', 'Negative']:\n",
    "            for file in glob.glob(os.path.join(path, label, '*.jpg')):\n",
    "                img = cv2.imread(file)\n",
    "                if img is not None:\n",
    "                    img = cv2.resize(img, (128, 128))\n",
    "                    lbp_feat = extract_lbp_features(img)\n",
    "                    \n",
    "                    if augment:\n",
    "                        img = img.reshape((1,) + img.shape)\n",
    "                        aug_iter = datagen.flow(img)\n",
    "                        img = next(aug_iter)[0]\n",
    "                    \n",
    "                    images.append(img)\n",
    "                    lbp_features.append(lbp_feat)\n",
    "                    labels.append(1 if label == 'Positive' else 0)\n",
    "\n",
    "                    if len(images) == batch_size:\n",
    "                        yield [np.array(images), np.array(lbp_features)], to_categorical(np.array(labels), num_classes=2)\n",
    "                        images = []\n",
    "                        lbp_features = []\n",
    "                        labels = []\n",
    "\n",
    "        if images:\n",
    "            yield [np.array(images), np.array(lbp_features)], to_categorical(np.array(labels), num_classes=2)\n",
    "\n",
    "# Build and compile a CNN model for image feature extraction\n",
    "def build_cnn_model(input_shape):\n",
    "    cnn_input = Input(shape=input_shape)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(cnn_input)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    cnn_model = Model(inputs=cnn_input, outputs=x)\n",
    "    return cnn_model\n",
    "\n",
    "input_shape = (128, 128, 3)\n",
    "\n",
    "# Build CNN model for image feature extraction\n",
    "cnn_model = build_cnn_model(input_shape)\n",
    "\n",
    "# Define the full model combining CNN and LBP features\n",
    "lbp_input = Input(shape=(26,))\n",
    "cnn_features = cnn_model.output\n",
    "combined = Concatenate()([cnn_features, lbp_input])\n",
    "x = Dense(128, activation='relu')(combined)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=[cnn_model.input, lbp_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define batch size and number of steps\n",
    "batch_size = 32\n",
    "train_steps = sum([len(files) for r, d, files in os.walk(train_path)]) // batch_size\n",
    "val_steps = sum([len(files) for r, d, files in os.walk(val_path)]) // batch_size\n",
    "test_steps = sum([len(files) for r, d, files in os.walk(test_path)]) // batch_size\n",
    "\n",
    "# Calculate class weights\n",
    "train_labels = []\n",
    "for label in ['Positive', 'Negative']:\n",
    "    for file in glob.glob(os.path.join(train_path, label, '*.jpg')):\n",
    "        train_labels.append(1 if label == 'Positive' else 0)\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Early stopping and model checkpoint\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Train the model with data augmentation\n",
    "model.fit(\n",
    "    image_lbp_generator(train_path, batch_size, augment=True),\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=10,\n",
    "    validation_data=image_lbp_generator(val_path, batch_size),\n",
    "    validation_steps=val_steps,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Manually load test data\n",
    "test_images = []\n",
    "test_lbp_features = []\n",
    "test_labels = []\n",
    "\n",
    "for label in ['Positive', 'Negative']:\n",
    "    for file in glob.glob(os.path.join(test_path, label, '*.jpg')):\n",
    "        img = cv2.imread(file)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (128, 128))\n",
    "            lbp_feat = extract_lbp_features(img)\n",
    "            test_images.append(img)\n",
    "            test_lbp_features.append(lbp_feat)\n",
    "            test_labels.append(1 if label == 'Positive' else 0)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_lbp_features = np.array(test_lbp_features)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict([test_images, test_lbp_features])\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Combined Model Classification Report:\")\n",
    "print(classification_report(test_labels, y_pred_classes, target_names=['Negative', 'Positive']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "784a3e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "126/126 [==============================] - ETA: 0s - loss: 1.0235 - accuracy: 0.4516"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/niteshyadav/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2042, in test_function  *\n        return step_function(self, iterator)\n    File \"/Users/niteshyadav/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2025, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/niteshyadav/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2013, in run_step  **\n        outputs = model.test_step(data)\n    File \"/Users/niteshyadav/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1893, in test_step\n        y_pred = self(x, training=False)\n    File \"/Users/niteshyadav/anaconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/niteshyadav/anaconda3/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_3' (type Functional).\n    \n    Input 0 of layer \"max_pooling2d_3\" is incompatible with the layer: expected ndim=4, found ndim=5. Full shape received: (None, None, None, None, 32)\n    \n    Call arguments received by layer 'model_3' (type Functional):\n      • inputs=('tf.Tensor(shape=(None, None, None, None, None), dtype=uint8)', 'tf.Tensor(shape=(None, None), dtype=float32)')\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 128\u001b[0m\n\u001b[1;32m    121\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    122\u001b[0m     EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m    123\u001b[0m     ModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m    124\u001b[0m     ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    125\u001b[0m ]\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Train the model with data augmentation\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_lbp_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_lbp_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Manually load test data\u001b[39;00m\n\u001b[1;32m    139\u001b[0m test_images \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/lx/79wrqbkn04x8tggrk8x3z4qr0000gn/T/__autograph_generated_filefpk61job.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/niteshyadav/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2042, in test_function  *\n        return step_function(self, iterator)\n    File \"/Users/niteshyadav/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2025, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/niteshyadav/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2013, in run_step  **\n        outputs = model.test_step(data)\n    File \"/Users/niteshyadav/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1893, in test_step\n        y_pred = self(x, training=False)\n    File \"/Users/niteshyadav/anaconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/niteshyadav/anaconda3/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_3' (type Functional).\n    \n    Input 0 of layer \"max_pooling2d_3\" is incompatible with the layer: expected ndim=4, found ndim=5. Full shape received: (None, None, None, None, 32)\n    \n    Call arguments received by layer 'model_3' (type Functional):\n      • inputs=('tf.Tensor(shape=(None, None, None, None, None), dtype=uint8)', 'tf.Tensor(shape=(None, None), dtype=float32)')\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Concatenate, Dropout, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Paths to the dataset folders\n",
    "train_path = \"/Users/niteshyadav/Lyme_Disease/train\"\n",
    "test_path = \"/Users/niteshyadav/Lyme_Disease/test\"\n",
    "val_path = \"/Users/niteshyadav/Lyme_Disease/val\"\n",
    "\n",
    "\n",
    "# Function to extract LBP features from the image\n",
    "def extract_lbp_features(image):\n",
    "    lbp = local_binary_pattern(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), P=8, R=1, method='uniform')\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, 27), range=(0, 26))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-6)\n",
    "    return hist\n",
    "\n",
    "# Generator to yield batches of images and LBP features\n",
    "def image_lbp_generator(path, batch_size=32, augment=False):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    ) if augment else ImageDataGenerator()\n",
    "    \n",
    "    while True:\n",
    "        images = []\n",
    "        lbp_features = []\n",
    "        labels = []\n",
    "        for label in ['Positive', 'Negative']:\n",
    "            for file in glob.glob(os.path.join(path, label, '*.jpg')):\n",
    "                img = cv2.imread(file)\n",
    "                if img is not None:\n",
    "                    img = cv2.resize(img, (128, 128))\n",
    "                    lbp_feat = extract_lbp_features(img)\n",
    "                    \n",
    "                    img = img.reshape((1,) + img.shape)\n",
    "                    if augment:\n",
    "                        img = next(datagen.flow(img))[0]\n",
    "                    \n",
    "                    images.append(img)\n",
    "                    lbp_features.append(lbp_feat)\n",
    "                    labels.append(1 if label == 'Positive' else 0)\n",
    "\n",
    "                    if len(images) == batch_size:\n",
    "                        yield [np.array(images), np.array(lbp_features)], to_categorical(np.array(labels), num_classes=2)\n",
    "                        images = []\n",
    "                        lbp_features = []\n",
    "                        labels = []\n",
    "\n",
    "        if images:\n",
    "            yield [np.array(images), np.array(lbp_features)], to_categorical(np.array(labels), num_classes=2)\n",
    "\n",
    "# Build and compile a CNN model for image feature extraction\n",
    "def build_cnn_model(input_shape):\n",
    "    cnn_input = Input(shape=input_shape)\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(cnn_input)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    cnn_model = Model(inputs=cnn_input, outputs=x)\n",
    "    return cnn_model\n",
    "\n",
    "input_shape = (128, 128, 3)\n",
    "\n",
    "# Build CNN model for image feature extraction\n",
    "cnn_model = build_cnn_model(input_shape)\n",
    "\n",
    "# Define the full model combining CNN and LBP features\n",
    "lbp_input = Input(shape=(26,))\n",
    "cnn_features = cnn_model.output\n",
    "combined = Concatenate()([cnn_features, lbp_input])\n",
    "x = Dense(128, activation='relu')(combined)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=[cnn_model.input, lbp_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define batch size and number of steps\n",
    "batch_size = 32\n",
    "train_steps = sum([len(files) for r, d, files in os.walk(train_path)]) // batch_size\n",
    "val_steps = sum([len(files) for r, d, files in os.walk(val_path)]) // batch_size\n",
    "test_steps = sum([len(files) for r, d, files in os.walk(test_path)]) // batch_size\n",
    "\n",
    "# Calculate class weights\n",
    "train_labels = []\n",
    "for label in ['Positive', 'Negative']:\n",
    "    for file in glob.glob(os.path.join(train_path, label, '*.jpg')):\n",
    "        train_labels.append(1 if label == 'Positive' else 0)\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_model.h5', save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)\n",
    "]\n",
    "\n",
    "# Train the model with data augmentation\n",
    "model.fit(\n",
    "    image_lbp_generator(train_path, batch_size, augment=True),\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=20,\n",
    "    validation_data=image_lbp_generator(val_path, batch_size),\n",
    "    validation_steps=val_steps,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Manually load test data\n",
    "test_images = []\n",
    "test_lbp_features = []\n",
    "test_labels = []\n",
    "\n",
    "for label in ['Positive', 'Negative']:\n",
    "    for file in glob.glob(os.path.join(test_path, label, '*.jpg')):\n",
    "        img = cv2.imread(file)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (128, 128))\n",
    "            lbp_feat = extract_lbp_features(img)\n",
    "            test_images.append(img)\n",
    "            test_lbp_features.append(lbp_feat)\n",
    "            test_labels.append(1 if label == 'Positive' else 0)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_lbp_features = np.array(test_lbp_features)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict([test_images, test_lbp_features])\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Combined Model Classification Report:\")\n",
    "print(classification_report(test_labels, y_pred_classes, target_names=['Negative', 'Positive']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42a23bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "126/126 [==============================] - 20s 159ms/step - loss: 0.9115 - accuracy: 0.4501 - val_loss: 0.7655 - val_accuracy: 0.1979 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "  1/126 [..............................] - ETA: 9s - loss: 0.4838 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niteshyadav/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 20s 160ms/step - loss: 0.7896 - accuracy: 0.4544 - val_loss: 0.7246 - val_accuracy: 0.1603 - lr: 0.0010\n",
      "Epoch 3/20\n",
      " 54/126 [===========>..................] - ETA: 10s - loss: 1.1196 - accuracy: 0.4520"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 100\u001b[0m\n\u001b[1;32m     93\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     94\u001b[0m     EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     95\u001b[0m     ModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     96\u001b[0m     ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     97\u001b[0m ]\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Train the model with data augmentation\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_lbp_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_lbp_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Manually load test data\u001b[39;00m\n\u001b[1;32m    111\u001b[0m test_images \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m   \u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Corrected data generator function\n",
    "def image_lbp_generator(path, batch_size=32, augment=False):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    ) if augment else ImageDataGenerator()\n",
    "\n",
    "    while True:\n",
    "        images = []\n",
    "        lbp_features = []\n",
    "        labels = []\n",
    "        for label in ['Positive', 'Negative']:\n",
    "            for file in glob.glob(os.path.join(path, label, '*.jpg')):\n",
    "                img = cv2.imread(file)\n",
    "                if img is not None:\n",
    "                    img = cv2.resize(img, (128, 128))\n",
    "                    lbp_feat = extract_lbp_features(img)\n",
    "                    \n",
    "                    if augment:\n",
    "                        img = img.reshape((1,) + img.shape)  # Adding batch dimension for augmentation\n",
    "                        img = next(datagen.flow(img, batch_size=1))[0]\n",
    "                    \n",
    "                    images.append(img)\n",
    "                    lbp_features.append(lbp_feat)\n",
    "                    labels.append(1 if label == 'Positive' else 0)\n",
    "\n",
    "                    if len(images) == batch_size:\n",
    "                        yield [np.array(images), np.array(lbp_features)], to_categorical(np.array(labels), num_classes=2)\n",
    "                        images = []\n",
    "                        lbp_features = []\n",
    "                        labels = []\n",
    "\n",
    "        if images:\n",
    "            yield [np.array(images), np.array(lbp_features)], to_categorical(np.array(labels), num_classes=2)\n",
    "\n",
    "# Build and compile a CNN model for image feature extraction\n",
    "def build_cnn_model(input_shape):\n",
    "    cnn_input = Input(shape=input_shape)\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(cnn_input)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    cnn_model = Model(inputs=cnn_input, outputs=x)\n",
    "    return cnn_model\n",
    "\n",
    "# Define the input shape and build the CNN model\n",
    "input_shape = (128, 128, 3)\n",
    "cnn_model = build_cnn_model(input_shape)\n",
    "\n",
    "# Define the full model combining CNN and LBP features\n",
    "lbp_input = Input(shape=(26,))\n",
    "cnn_features = cnn_model.output\n",
    "combined = Concatenate()([cnn_features, lbp_input])\n",
    "x = Dense(128, activation='relu')(combined)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=[cnn_model.input, lbp_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define batch size and number of steps\n",
    "batch_size = 32\n",
    "train_steps = sum([len(files) for r, d, files in os.walk(train_path)]) // batch_size\n",
    "val_steps = sum([len(files) for r, d, files in os.walk(val_path)]) // batch_size\n",
    "test_steps = sum([len(files) for r, d, files in os.walk(test_path)]) // batch_size\n",
    "\n",
    "# Calculate class weights\n",
    "train_labels = []\n",
    "for label in ['Positive', 'Negative']:\n",
    "    for file in glob.glob(os.path.join(train_path, label, '*.jpg')):\n",
    "        train_labels.append(1 if label == 'Positive' else 0)\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_model.h5', save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)\n",
    "]\n",
    "\n",
    "# Train the model with data augmentation\n",
    "model.fit(\n",
    "    image_lbp_generator(train_path, batch_size, augment=True),\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=20,\n",
    "    validation_data=image_lbp_generator(val_path, batch_size),\n",
    "    validation_steps=val_steps,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Manually load test data\n",
    "test_images = []\n",
    "test_lbp_features = []\n",
    "test_labels = []\n",
    "\n",
    "for label in ['Positive', 'Negative']:\n",
    "    for file in glob.glob(os.path.join(test_path, label, '*.jpg')):\n",
    "        img = cv2.imread(file)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (128, 128))\n",
    "            lbp_feat = extract_lbp_features(img)\n",
    "            test_images.append(img)\n",
    "            test_lbp_features.append(lbp_feat)\n",
    "            test_labels.append(1 if label == 'Positive' else 0)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_lbp_features = np.array(test_lbp_features)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict([test_images, test_lbp_features])\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Combined Model Classification Report:\")\n",
    "print(classification_report(test_labels, y_pred_classes, target_names=['Negative', 'Positive']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efe73960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85       412\n",
      "           1       0.34      0.34      0.34        95\n",
      "\n",
      "    accuracy                           0.75       507\n",
      "   macro avg       0.59      0.59      0.59       507\n",
      "weighted avg       0.75      0.75      0.75       507\n",
      "\n",
      "Confusion Matrix:\n",
      "[[349  63]\n",
      " [ 63  32]]\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85       412\n",
      "           1       0.31      0.27      0.29        94\n",
      "\n",
      "    accuracy                           0.75       506\n",
      "   macro avg       0.58      0.57      0.57       506\n",
      "weighted avg       0.74      0.75      0.75       506\n",
      "\n",
      "Validation Confusion Matrix:\n",
      "[[357  55]\n",
      " [ 69  25]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Parameters for LBP\n",
    "radius = 1\n",
    "n_points = 8 * radius\n",
    "METHOD = 'uniform'\n",
    "\n",
    "# Paths to the dataset folders\n",
    "train_path = \"/Users/niteshyadav/Lyme_Disease/train\"\n",
    "test_path = \"/Users/niteshyadav/Lyme_Disease/test\"\n",
    "val_path = \"/Users/niteshyadav/Lyme_Disease/val\"\n",
    "\n",
    "# Function to load images and extract LBP features\n",
    "def load_images_and_extract_features(directory):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for label in [\"Negative\", \"Positive\"]:\n",
    "        class_dir = os.path.join(directory, label)\n",
    "        for image_name in os.listdir(class_dir):\n",
    "            image_path = os.path.join(class_dir, image_name)\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, (128, 128))\n",
    "            lbp = local_binary_pattern(image, n_points, radius, METHOD)\n",
    "            hist, _ = np.histogram(lbp, bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n",
    "            hist = hist.astype(\"float\")\n",
    "            hist /= (hist.sum() + 1e-6)  # Normalize the histogram\n",
    "            features.append(hist)\n",
    "            labels.append(label)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Load and extract features from train, test, and validation sets\n",
    "X_train, y_train = load_images_and_extract_features(train_path)\n",
    "X_test, y_test = load_images_and_extract_features(test_path)\n",
    "X_val, y_val = load_images_and_extract_features(val_path)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "y_val = le.transform(y_val)\n",
    "\n",
    "# Handle imbalanced data using SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Evaluate the classifier\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_val_pred = clf.predict(X_val)\n",
    "print(\"Validation Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(\"Validation Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7a0468b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/path/to/augmented/train/Positive/Positive_0_50.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m augmented_train_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/path/to/augmented/train/Positive\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Augment positive images in the training set\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[43maugment_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugmented_train_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPositive\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 23\u001b[0m, in \u001b[0;36maugment_images\u001b[0;34m(directory, save_to_dir, label)\u001b[0m\n\u001b[1;32m     21\u001b[0m image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(image, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     22\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m datagen\u001b[38;5;241m.\u001b[39mflow(image, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, save_to_dir\u001b[38;5;241m=\u001b[39msave_to_dir, save_prefix\u001b[38;5;241m=\u001b[39mlabel, save_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjpeg\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     24\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m20\u001b[39m:  \u001b[38;5;66;03m# Number of augmentations per image\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/preprocessing/image.py:156\u001b[0m, in \u001b[0;36mIterator.__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/preprocessing/image.py:168\u001b[0m, in \u001b[0;36mIterator.next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m     index_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_generator)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# The transformation of images is not under thread lock\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# so it can be done in parallel\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_batches_of_transformed_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_array\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/preprocessing/image.py:818\u001b[0m, in \u001b[0;36mNumpyArrayIterator._get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    809\u001b[0m         img \u001b[38;5;241m=\u001b[39m image_utils\u001b[38;5;241m.\u001b[39marray_to_img(\n\u001b[1;32m    810\u001b[0m             batch_x[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_format, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    811\u001b[0m         )\n\u001b[1;32m    812\u001b[0m         fname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{prefix}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{index}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{hash}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{format}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    813\u001b[0m             prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_prefix,\n\u001b[1;32m    814\u001b[0m             index\u001b[38;5;241m=\u001b[39mj,\n\u001b[1;32m    815\u001b[0m             \u001b[38;5;28mhash\u001b[39m\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1e4\u001b[39m),\n\u001b[1;32m    816\u001b[0m             \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_format,\n\u001b[1;32m    817\u001b[0m         )\n\u001b[0;32m--> 818\u001b[0m         \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    819\u001b[0m batch_x_miscs \u001b[38;5;241m=\u001b[39m [xx[index_array] \u001b[38;5;28;01mfor\u001b[39;00m xx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_misc]\n\u001b[1;32m    820\u001b[0m output \u001b[38;5;241m=\u001b[39m (batch_x \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batch_x_miscs \u001b[38;5;28;01melse\u001b[39;00m [batch_x] \u001b[38;5;241m+\u001b[39m batch_x_miscs,)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/PIL/Image.py:2428\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2426\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2427\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2428\u001b[0m         fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2430\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2431\u001b[0m     save_handler(\u001b[38;5;28mself\u001b[39m, fp, filename)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/path/to/augmented/train/Positive/Positive_0_50.jpeg'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Initialize the ImageDataGenerator with augmentation settings\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Function to augment the images\n",
    "def augment_images(directory, save_to_dir, label):\n",
    "    class_dir = os.path.join(directory, label)\n",
    "    for image_name in os.listdir(class_dir):\n",
    "        image_path = os.path.join(class_dir, image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        i = 0\n",
    "        for batch in datagen.flow(image, batch_size=1, save_to_dir=save_to_dir, save_prefix=label, save_format='jpeg'):\n",
    "            i += 1\n",
    "            if i > 20:  # Number of augmentations per image\n",
    "                break\n",
    "\n",
    "# Paths to save augmented images\n",
    "augmented_train_path = \"/path/to/augmented/train/Positive\"\n",
    "\n",
    "# Augment positive images in the training set\n",
    "augment_images(train_path, augmented_train_path, 'Positive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb38d3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
