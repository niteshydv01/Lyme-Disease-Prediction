{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f2a511d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4038 images belonging to 2 classes.\n",
      "Found 506 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niteshyadav/anaconda3/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niteshyadav/anaconda3/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 229ms/step - accuracy: 0.7969 - loss: 0.4904 - val_accuracy: 0.8188 - val_loss: 0.4845\n",
      "Epoch 2/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.8125 - loss: 0.4942 - val_accuracy: 0.7308 - val_loss: 0.6403\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niteshyadav/anaconda3/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 230ms/step - accuracy: 0.8238 - loss: 0.4668 - val_accuracy: 0.8167 - val_loss: 0.4751\n",
      "Epoch 4/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.9375 - loss: 0.2952 - val_accuracy: 0.7692 - val_loss: 0.5667\n",
      "Epoch 5/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 231ms/step - accuracy: 0.8011 - loss: 0.4995 - val_accuracy: 0.8083 - val_loss: 0.4913\n",
      "Epoch 6/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.9062 - loss: 0.3292 - val_accuracy: 0.9231 - val_loss: 0.3132\n",
      "Epoch 7/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 232ms/step - accuracy: 0.8091 - loss: 0.4863 - val_accuracy: 0.8125 - val_loss: 0.4773\n",
      "Epoch 8/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.8750 - loss: 0.3764 - val_accuracy: 0.8462 - val_loss: 0.4518\n",
      "Epoch 9/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 235ms/step - accuracy: 0.8146 - loss: 0.4780 - val_accuracy: 0.8167 - val_loss: 0.4806\n",
      "Epoch 10/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7500 - loss: 0.6106 - val_accuracy: 0.7692 - val_loss: 0.5173\n",
      "Epoch 11/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 233ms/step - accuracy: 0.8128 - loss: 0.4817 - val_accuracy: 0.8167 - val_loss: 0.4895\n",
      "Epoch 12/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7812 - loss: 0.5451 - val_accuracy: 0.7692 - val_loss: 0.5252\n",
      "Epoch 13/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 236ms/step - accuracy: 0.8169 - loss: 0.4742 - val_accuracy: 0.8250 - val_loss: 0.4589\n",
      "Epoch 14/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.8750 - loss: 0.3806 - val_accuracy: 0.6154 - val_loss: 0.8181\n",
      "Epoch 15/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 235ms/step - accuracy: 0.7978 - loss: 0.4992 - val_accuracy: 0.8146 - val_loss: 0.4754\n",
      "Epoch 16/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.8125 - loss: 0.4768 - val_accuracy: 0.8077 - val_loss: 0.4866\n",
      "Epoch 17/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 233ms/step - accuracy: 0.8049 - loss: 0.4900 - val_accuracy: 0.8083 - val_loss: 0.4851\n",
      "Epoch 18/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7500 - loss: 0.5725 - val_accuracy: 0.9231 - val_loss: 0.3289\n",
      "Epoch 19/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 235ms/step - accuracy: 0.8100 - loss: 0.4822 - val_accuracy: 0.8167 - val_loss: 0.4706\n",
      "Epoch 20/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.9062 - loss: 0.3484 - val_accuracy: 0.7692 - val_loss: 0.5458\n",
      "Epoch 21/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 236ms/step - accuracy: 0.8191 - loss: 0.4680 - val_accuracy: 0.8083 - val_loss: 0.4865\n",
      "Epoch 22/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.7188 - loss: 0.5731 - val_accuracy: 0.9231 - val_loss: 0.3525\n",
      "Epoch 23/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 235ms/step - accuracy: 0.8087 - loss: 0.4825 - val_accuracy: 0.8146 - val_loss: 0.4750\n",
      "Epoch 24/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7500 - loss: 0.5136 - val_accuracy: 0.8077 - val_loss: 0.4399\n",
      "Epoch 25/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 231ms/step - accuracy: 0.8200 - loss: 0.4688 - val_accuracy: 0.8146 - val_loss: 0.4777\n",
      "Epoch 26/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.8125 - loss: 0.4905 - val_accuracy: 0.8077 - val_loss: 0.4973\n",
      "Epoch 27/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 232ms/step - accuracy: 0.8130 - loss: 0.4767 - val_accuracy: 0.8167 - val_loss: 0.4873\n",
      "Epoch 28/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.7500 - loss: 0.5592 - val_accuracy: 0.7692 - val_loss: 0.6046\n",
      "Epoch 29/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 228ms/step - accuracy: 0.8152 - loss: 0.4739 - val_accuracy: 0.8083 - val_loss: 0.4778\n",
      "Epoch 30/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.8750 - loss: 0.3612 - val_accuracy: 0.9231 - val_loss: 0.3118\n",
      "Found 507 images belonging to 2 classes.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.7943 - loss: 0.4960\n",
      "Test accuracy: 0.8083\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Function to convert an image to thermal\n",
    "def convert_to_thermal(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    thermal_image = cv2.applyColorMap(image, cv2.COLORMAP_JET)\n",
    "    return Image.fromarray(thermal_image)\n",
    "\n",
    "# Convert all images in a directory to thermal images\n",
    "def convert_directory_to_thermal(input_dir, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                input_path = os.path.join(root, file)\n",
    "                relative_path = os.path.relpath(input_path, input_dir)\n",
    "                output_path = os.path.join(output_dir, relative_path)\n",
    "\n",
    "                # Create output directory if it doesn't exist\n",
    "                os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "                thermal_image = convert_to_thermal(input_path)\n",
    "                thermal_image.save(output_path)\n",
    "\n",
    "# Paths to original and thermal image directories\n",
    "train_path = \"/Users/niteshyadav/Lyme_Disease/train\"\n",
    "test_path = \"/Users/niteshyadav/Lyme_Disease/test\"\n",
    "val_path = \"/Users/niteshyadav/Lyme_Disease/val\"\n",
    "\n",
    "thermal_train_path = \"/Users/niteshyadav/Lyme_Disease/thermal_img/train\"\n",
    "thermal_test_path = \"/Users/niteshyadav/Lyme_Disease/thermal_img/test\"\n",
    "thermal_val_path = \"/Users/niteshyadav/Lyme_Disease/thermal_img/val\"\n",
    "\n",
    "# Convert the datasets to thermal images\n",
    "convert_directory_to_thermal(train_path, thermal_train_path)\n",
    "convert_directory_to_thermal(test_path, thermal_test_path)\n",
    "convert_directory_to_thermal(val_path, thermal_val_path)\n",
    "\n",
    "# Data Augmentation and Data Generator for Thermal Images\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    thermal_train_path,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    thermal_val_path,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Model Architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the Model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    thermal_test_path,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f'Test accuracy: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7401f835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n",
      "libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n",
      "libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n",
      "libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n",
      "libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n",
      "libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n",
      "libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n",
      "libpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/colormap.cpp:738: error: (-2:Unspecified error) in function 'void cv::colormap::ColorMap::operator()(cv::InputArray, cv::OutputArray) const'\n> Not supported (expected: 'src.dims == 2'), where\n>     'src.dims' is 0\n> must be equal to\n>     '2' is 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m thermal_val_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/niteshyadav/Lyme_Disease/val_thermal_rashes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Convert the datasets to thermal images\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[43mconvert_directory_to_thermal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthermal_train_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#convert_directory_to_thermal(test_path, thermal_test_path)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m convert_directory_to_thermal(val_path, thermal_val_path)\n",
      "Cell \u001b[0;32mIn[5], line 28\u001b[0m, in \u001b[0;36mconvert_directory_to_thermal\u001b[0;34m(input_dir, output_dir)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Create output directory if it doesn't exist\u001b[39;00m\n\u001b[1;32m     26\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(output_path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 28\u001b[0m thermal_image \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_thermal\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m thermal_image\u001b[38;5;241m.\u001b[39msave(output_path)\n",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m, in \u001b[0;36mconvert_to_thermal\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_thermal\u001b[39m(image_path):\n\u001b[1;32m      9\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[0;32m---> 10\u001b[0m     thermal_image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapplyColorMap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLORMAP_JET\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mfromarray(thermal_image)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/colormap.cpp:738: error: (-2:Unspecified error) in function 'void cv::colormap::ColorMap::operator()(cv::InputArray, cv::OutputArray) const'\n> Not supported (expected: 'src.dims == 2'), where\n>     'src.dims' is 0\n> must be equal to\n>     '2' is 2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Function to convert an image to thermal\n",
    "def convert_to_thermal(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    thermal_image = cv2.applyColorMap(image, cv2.COLORMAP_JET)\n",
    "    return Image.fromarray(thermal_image)\n",
    "\n",
    "# Convert all images in a directory to thermal images\n",
    "def convert_directory_to_thermal(input_dir, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                input_path = os.path.join(root, file)\n",
    "                relative_path = os.path.relpath(input_path, input_dir)\n",
    "                output_path = os.path.join(output_dir, relative_path)\n",
    "\n",
    "                # Create output directory if it doesn't exist\n",
    "                os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "                thermal_image = convert_to_thermal(input_path)\n",
    "                thermal_image.save(output_path)\n",
    "\n",
    "# Paths to original and thermal image directories\n",
    "\n",
    "#test_path = \"/Users/niteshyadav/Lyme_Disease/test\"\n",
    "\n",
    "# Paths to the dataset folders\n",
    "train_path = \"/Users/niteshyadav/Lyme_Disease/Train_rash/Train_2_Cases\"\n",
    "val_path = \"/Users/niteshyadav/Lyme_Disease/Validation_rash/Validation_2_Cases\"\n",
    "\n",
    "thermal_train_path = \"/Users/niteshyadav/Lyme_Disease/train_thermal_rashes\"\n",
    "#thermal_test_path = \"/Users/niteshyadav/Lyme_Disease/thermal_img/test\"\n",
    "thermal_val_path = \"/Users/niteshyadav/Lyme_Disease/val_thermal_rashes\"\n",
    "\n",
    "# Convert the datasets to thermal images\n",
    "convert_directory_to_thermal(train_path, thermal_train_path)\n",
    "#convert_directory_to_thermal(test_path, thermal_test_path)\n",
    "convert_directory_to_thermal(val_path, thermal_val_path)\n",
    "\n",
    "# Data Augmentation and Data Generator for Thermal Images\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    thermal_train_path,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    thermal_val_path,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Model Architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the Model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    thermal_test_path,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f'Test accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b3ffae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
